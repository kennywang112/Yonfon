{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860154d-5760-4c6e-a55a-f65e41c147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e21775-11df-4b77-b78f-f92ad77691e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 12:11:40.458901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(\"model_epoch_06.h5\", compile=False)\n",
    "model_config = loaded_model.get_config()\n",
    "#loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40fcfd1b-0bbf-41f6-bcb5-73951ca3485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(img):\n",
    "\n",
    "    # Resize the image to match the input shape of your model\n",
    "    img = img.resize((256, 256))  # Adjust the size as needed\n",
    "    # Convert the image to a NumPy array\n",
    "    img_np = np.array(img)\n",
    "    \n",
    "    # Preprocess the image to match the model's input requirements\n",
    "    img_np = keras_image.img_to_array(img_np)\n",
    "    \n",
    "    img_for_plot = img_np / 255.0  # Normalize the image if necessary\n",
    "    \n",
    "    img_np = np.expand_dims(img_np, axis=0)  # Add a batch dimension\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = loaded_model.predict(img_np)\n",
    "    return img_for_plot, predictions\n",
    "\n",
    "def image_mod(img):\n",
    "    \n",
    "    image, predictions = pred(img)\n",
    "\n",
    "    print(predictions)\n",
    "    \n",
    "    result = \"\"\n",
    "    \n",
    "    if predictions[0][0] == 0.0:\n",
    "\n",
    "        result = \"fake image\"\n",
    "    else :\n",
    "        \n",
    "        result = \"true image\"\n",
    "\n",
    "    return result\n",
    "\n",
    "def chatbtn(content):\n",
    "    \n",
    "    print(content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d534885-2796-4907-9e69-9ec81d275c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\"<h1 align=\"center\">AIè‡‰éƒ¨è¾¨è­˜ðŸš€</h1>\"\"\"\n",
    "                \n",
    "with gr.Blocks(css = \"\"\".gradio-container {background-color: #3f7791}\"\"\") as demo:\n",
    "    gr.HTML(title)\n",
    "    gr.HTML('''<center><a href=\"https://github.com/kennywang112?tab=repositories\" alt=\"GitHub Repo\"></a></center>''')\n",
    "    with gr.Row():\n",
    "        with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "            chatbot = gr.Chatbot(elem_id='chatbot')\n",
    "            inputs = gr.Textbox(placeholder= \"Hi there!\", label= \"Type an input and press Enter\")\n",
    "            state = gr.State([])\n",
    "            btn = gr.Button('ask') \n",
    "            \n",
    "        btn.click(chatbtn, [inputs], [])\n",
    "\n",
    "        with gr.Column(elem_id = \"col_container\"):\n",
    "            \n",
    "            gr.Interface(\n",
    "                image_mod,\n",
    "                gr.Image(type=\"pil\"),\n",
    "                \"text\",\n",
    "                examples=[\n",
    "                    os.path.join(\"images/real_face0.jpeg\"),\n",
    "                    os.path.join(\"images/real_face1.jpeg\"),\n",
    "                    os.path.join(\"images/fake_face1.jpeg\"),\n",
    "                    os.path.join(\"images/fake_face0.jpeg\"),\n",
    "                ],\n",
    "            )\n",
    "    \n",
    "demo.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bb295-2557-471f-8935-65fd63ac56d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
